{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6tHqe7chAo67",
        "outputId": "8eebc842-b7f4-458d-fc22-0c8951ba0b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required packages...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Packages installed successfully!\n",
            "‚úÖ Libraries imported successfully!\n",
            "\n",
            "==================================================\n",
            "STEP 1: LOAD TRAINING DATA\n",
            "==================================================\n",
            "Loading training dataset: exercise_angles.csv\n",
            "‚úÖ Training file loaded: exercise_angles.csv\n",
            "‚úÖ Dataset loaded with shape: (31033, 12)\n",
            "‚úÖ Columns: ['Side', 'Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Knee_Angle', 'Ankle_Angle', 'Shoulder_Ground_Angle', 'Elbow_Ground_Angle', 'Hip_Ground_Angle', 'Knee_Ground_Angle', 'Ankle_Ground_Angle', 'Label']\n",
            "‚úÖ Unique labels: ['Jumping Jacks' 'Squats' 'Push Ups' 'Pull ups' 'Russian twists']\n",
            "\n",
            "==================================================\n",
            "STEP 2: DATA PREPROCESSING\n",
            "==================================================\n",
            "‚úÖ Original training size: 21723\n",
            "‚úÖ After SMOTE training size: 34175\n",
            "‚úÖ Test size: 9310\n",
            "\n",
            "==================================================\n",
            "STEP 3: MODEL TRAINING\n",
            "==================================================\n",
            "Training Random Forest...\n",
            "Training XGBoost...\n",
            "Training LightGBM...\n",
            "Creating ensemble model...\n",
            "‚úÖ All models trained successfully!\n",
            "\n",
            "==================================================\n",
            "STEP 4: MODEL EVALUATION\n",
            "==================================================\n",
            "Random Forest Accuracy: 0.9668\n",
            "XGBoost Accuracy: 0.9660\n",
            "LightGBM Accuracy: 0.9619\n",
            "Ensemble Accuracy: 0.9662\n",
            "\n",
            "üèÜ Best Model: Random Forest with accuracy: 0.9668\n",
            "\n",
            "Detailed Classification Report for Random Forest:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            " Jumping Jacks       0.97      0.96      0.97      1563\n",
            "      Pull ups       0.96      0.96      0.96      1998\n",
            "      Push Ups       0.97      0.99      0.98      2929\n",
            "Russian twists       0.98      0.97      0.97      1321\n",
            "        Squats       0.95      0.93      0.94      1499\n",
            "\n",
            "      accuracy                           0.97      9310\n",
            "     macro avg       0.97      0.96      0.96      9310\n",
            "  weighted avg       0.97      0.97      0.97      9310\n",
            "\n",
            "\n",
            "==================================================\n",
            "STEP 5: SAVING MODELS\n",
            "==================================================\n",
            "‚úÖ Models and encoders saved successfully!\n",
            "Files saved:\n",
            "- best_exercise_model.pkl\n",
            "- label_encoder.pkl\n",
            "- side_encoder.pkl\n",
            "\n",
            "==================================================\n",
            "STEP 6: UPLOAD NEW DATA FOR PREDICTION\n",
            "==================================================\n",
            "Loading new data file for prediction: new_exercise_data.csv\n",
            "‚úÖ New data loaded with shape: (9, 11)\n",
            "\n",
            "==================================================\n",
            "STEP 7: MAKING PREDICTIONS\n",
            "==================================================\n",
            "‚úÖ Predictions completed!\n",
            "Total predictions made: 9\n",
            "\n",
            "First 10 predictions:\n",
            "   Side  Shoulder_Angle  Elbow_Angle   Hip_Angle Predicted_Label\n",
            "0  left       10.639208   174.466813  174.785143   Jumping Jacks\n",
            "1  left       10.590342   174.428706  174.765041   Jumping Jacks\n",
            "2  left       10.546746   174.489431  174.785790   Jumping Jacks\n",
            "3  left       10.487682   174.614913  174.759542   Jumping Jacks\n",
            "4  left       10.412107   174.758503  174.737721   Jumping Jacks\n",
            "5  left       10.333750   174.896478  174.717610   Jumping Jacks\n",
            "6  left       10.264989   175.019119  174.688875   Jumping Jacks\n",
            "7  left       10.184175   175.145197  174.676467   Jumping Jacks\n",
            "8  left       10.123361   175.358891  174.640657   Jumping Jacks\n",
            "\n",
            "Prediction distribution:\n",
            "Jumping Jacks: 9 (100.0%)\n",
            "\n",
            "‚úÖ Results saved to 'exercise_predictions_results.csv'\n",
            "\n",
            "Downloading results file...\n",
            "‚ùå Error in prediction phase: name 'files' is not defined\n",
            "You can still use the trained model later by loading the saved files.\n",
            "\n",
            "==================================================\n",
            "HOW TO USE THE SAVED MODEL LATER\n",
            "==================================================\n",
            "\n",
            "To use the saved model later, run this code:\n",
            "\n",
            "import joblib\n",
            "import pandas as pd\n",
            "\n",
            "# Load saved components\n",
            "model = joblib.load('best_exercise_model.pkl')\n",
            "label_encoder = joblib.load('label_encoder.pkl')\n",
            "side_encoder = joblib.load('side_encoder.pkl')\n",
            "\n",
            "# Load your new data\n",
            "new_data = pd.read_csv('your_new_data.csv')\n",
            "\n",
            "# Prepare features\n",
            "new_data['Side_encoded'] = side_encoder.transform(new_data['Side'])\n",
            "feature_columns = ['Side_encoded', 'Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Knee_Angle',\n",
            "                  'Ankle_Angle', 'Shoulder_Ground_Angle', 'Elbow_Ground_Angle',\n",
            "                  'Hip_Ground_Angle', 'Knee_Ground_Angle', 'Ankle_Ground_Angle']\n",
            "X_new = new_data[feature_columns]\n",
            "\n",
            "# Make predictions\n",
            "predictions = model.predict(X_new)\n",
            "predicted_labels = label_encoder.inverse_transform(predictions)\n",
            "\n",
            "# Add to results\n",
            "new_data['Predicted_Label'] = predicted_labels\n",
            "    \n",
            "\n",
            "üéâ Process completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Complete Exercise Prediction Code for Google Colab\n",
        "# Run this entire cell to train model and predict on new data\n",
        "\n",
        "# Step 1: Install required packages\n",
        "print(\"Installing required packages...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    packages = ['catboost', 'lightgbm', 'xgboost', 'imbalanced-learn']\n",
        "    for package in packages:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
        "\n",
        "try:\n",
        "    install_packages()\n",
        "    print(\"‚úÖ Packages installed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error installing packages: {e}\")\n",
        "\n",
        "# Step 2: Import all necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "\n",
        "# Step 3: Load training data\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STEP 1: LOAD TRAINING DATA\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Load training data from local file\n",
        "training_file = 'exercise_angles.csv'\n",
        "print(f\"Loading training dataset: {training_file}\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(training_file)\n",
        "    print(f\"‚úÖ Training file loaded: {training_file}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå File not found: {training_file}\")\n",
        "    print(\"Please make sure 'exercise_angles.csv' is in the same directory as this notebook.\")\n",
        "    raise\n",
        "\n",
        "print(f\"‚úÖ Dataset loaded with shape: {df.shape}\")\n",
        "print(f\"‚úÖ Columns: {list(df.columns)}\")\n",
        "print(f\"‚úÖ Unique labels: {df['Label'].unique()}\")\n",
        "\n",
        "# Step 4: Data preprocessing\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STEP 2: DATA PREPROCESSING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create label encoders\n",
        "side_encoder = LabelEncoder()\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode categorical columns\n",
        "df['Side_encoded'] = side_encoder.fit_transform(df['Side'])\n",
        "df['Label_encoded'] = label_encoder.fit_transform(df['Label'])\n",
        "\n",
        "# Prepare features and target\n",
        "feature_columns = ['Side_encoded', 'Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Knee_Angle',\n",
        "                  'Ankle_Angle', 'Shoulder_Ground_Angle', 'Elbow_Ground_Angle',\n",
        "                  'Hip_Ground_Angle', 'Knee_Ground_Angle', 'Ankle_Ground_Angle']\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df['Label_encoded']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Apply SMOTE for class balancing\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(f\"‚úÖ Original training size: {X_train.shape[0]}\")\n",
        "print(f\"‚úÖ After SMOTE training size: {X_train_res.shape[0]}\")\n",
        "print(f\"‚úÖ Test size: {X_test.shape[0]}\")\n",
        "\n",
        "# Step 5: Model training\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STEP 3: MODEL TRAINING\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Train Random Forest\n",
        "print(\"Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Train XGBoost\n",
        "print(\"Training XGBoost...\")\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Train LightGBM\n",
        "print(\"Training LightGBM...\")\n",
        "lgb_model = LGBMClassifier(random_state=42, verbose=-1)\n",
        "lgb_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Create ensemble model\n",
        "print(\"Creating ensemble model...\")\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgb', lgb_model)\n",
        "    ],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "ensemble_model.fit(X_train_res, y_train_res)\n",
        "\n",
        "print(\"‚úÖ All models trained successfully!\")\n",
        "\n",
        "# Step 6: Model evaluation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STEP 4: MODEL EVALUATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "models = {\n",
        "    'Random Forest': rf_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'LightGBM': lgb_model,\n",
        "    'Ensemble': ensemble_model\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "best_model_name = \"\"\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = model\n",
        "        best_model_name = name\n",
        "\n",
        "print(f\"\\nüèÜ Best Model: {best_model_name} with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "# Detailed classification report for best model\n",
        "print(f\"\\nDetailed Classification Report for {best_model_name}:\")\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_best, target_names=label_encoder.classes_))\n",
        "\n",
        "# Step 7: Save models and encoders\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STEP 5: SAVING MODELS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Save the best model and encoders\n",
        "joblib.dump(best_model, 'best_exercise_model.pkl')\n",
        "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
        "joblib.dump(side_encoder, 'side_encoder.pkl')\n",
        "\n",
        "print(\"‚úÖ Models and encoders saved successfully!\")\n",
        "print(\"Files saved:\")\n",
        "print(\"- best_exercise_model.pkl\")\n",
        "print(\"- label_encoder.pkl\")\n",
        "print(\"- side_encoder.pkl\")\n",
        "\n",
        "# Step 8: Upload new data for prediction\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"STEP 6: UPLOAD NEW DATA FOR PREDICTION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    # Load new data from local file\n",
        "    new_data_file = 'new_exercise_data.csv'  # Change this to your actual file name\n",
        "    print(f\"Loading new data file for prediction: {new_data_file}\")\n",
        "\n",
        "    # Load new data\n",
        "    new_data = pd.read_csv(new_data_file)\n",
        "    print(f\"‚úÖ New data loaded with shape: {new_data.shape}\")\n",
        "\n",
        "    # Step 9: Make predictions\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"STEP 7: MAKING PREDICTIONS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Prepare new data\n",
        "    new_data_copy = new_data.copy()\n",
        "\n",
        "    # Encode Side column\n",
        "    new_data_copy['Side_encoded'] = side_encoder.transform(new_data_copy['Side'])\n",
        "\n",
        "    # Prepare features for prediction\n",
        "    X_new = new_data_copy[feature_columns]\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_numeric = best_model.predict(X_new)\n",
        "\n",
        "    # Convert predictions back to original labels\n",
        "    predicted_labels = label_encoder.inverse_transform(y_pred_numeric)\n",
        "\n",
        "    # Add predictions to the original data\n",
        "    result_data = new_data.copy()\n",
        "    result_data['Predicted_Label'] = predicted_labels\n",
        "\n",
        "    # Display results\n",
        "    print(\"‚úÖ Predictions completed!\")\n",
        "    print(f\"Total predictions made: {len(predicted_labels)}\")\n",
        "\n",
        "    print(\"\\nFirst 10 predictions:\")\n",
        "    display_cols = ['Side', 'Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Predicted_Label']\n",
        "    available_cols = [col for col in display_cols if col in result_data.columns]\n",
        "    print(result_data[available_cols].head(10))\n",
        "\n",
        "    print(\"\\nPrediction distribution:\")\n",
        "    prediction_counts = pd.Series(predicted_labels).value_counts()\n",
        "    for label, count in prediction_counts.items():\n",
        "        percentage = (count / len(predicted_labels)) * 100\n",
        "        print(f\"{label}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "    # Save results\n",
        "    result_data.to_csv('exercise_predictions_results.csv', index=False)\n",
        "    print(\"\\n‚úÖ Results saved to 'exercise_predictions_results.csv'\")\n",
        "\n",
        "    # Download the results\n",
        "    print(\"\\nDownloading results file...\")\n",
        "    files.download('exercise_predictions_results.csv')\n",
        "\n",
        "    # Step 10: Summary\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"‚úÖ Best Model: {best_model_name}\")\n",
        "    print(f\"‚úÖ Model Accuracy: {best_accuracy:.4f}\")\n",
        "    print(f\"‚úÖ Total Predictions: {len(predicted_labels)}\")\n",
        "    print(f\"‚úÖ Unique Exercises Predicted: {len(prediction_counts)}\")\n",
        "    print(\"‚úÖ Results downloaded successfully!\")\n",
        "\n",
        "    print(\"\\nExercise Types Found:\")\n",
        "    for exercise in prediction_counts.index:\n",
        "        print(f\"- {exercise}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error in prediction phase: {e}\")\n",
        "    print(\"You can still use the trained model later by loading the saved files.\")\n",
        "\n",
        "    # Show how to use the model later\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"HOW TO USE THE SAVED MODEL LATER\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"\"\"\n",
        "To use the saved model later, run this code:\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load saved components\n",
        "model = joblib.load('best_exercise_model.pkl')\n",
        "label_encoder = joblib.load('label_encoder.pkl')\n",
        "side_encoder = joblib.load('side_encoder.pkl')\n",
        "\n",
        "# Load your new data\n",
        "new_data = pd.read_csv('your_new_data.csv')\n",
        "\n",
        "# Prepare features\n",
        "new_data['Side_encoded'] = side_encoder.transform(new_data['Side'])\n",
        "feature_columns = ['Side_encoded', 'Shoulder_Angle', 'Elbow_Angle', 'Hip_Angle', 'Knee_Angle',\n",
        "                  'Ankle_Angle', 'Shoulder_Ground_Angle', 'Elbow_Ground_Angle',\n",
        "                  'Hip_Ground_Angle', 'Knee_Ground_Angle', 'Ankle_Ground_Angle']\n",
        "X_new = new_data[feature_columns]\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_new)\n",
        "predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "# Add to results\n",
        "new_data['Predicted_Label'] = predicted_labels\n",
        "    \"\"\")\n",
        "\n",
        "print(\"\\nüéâ Process completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
